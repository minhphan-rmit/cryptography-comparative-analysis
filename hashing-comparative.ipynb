{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automating the creation of test data paths\n",
    "def generate_file_paths(base_path, file_name_pattern, start, end, extension):\n",
    "    \"\"\"\n",
    "    Generates a list of file paths with a specified pattern.\n",
    "    \n",
    "    Args:\n",
    "    - base_path (str): The base directory path.\n",
    "    - file_name_pattern (str): The pattern of the file name with placeholders for numbering.\n",
    "    - start (int): The starting number for file names.\n",
    "    - end (int): The ending number for file names.\n",
    "    - extension (str): The file extension.\n",
    "    \n",
    "    Returns:\n",
    "    - List of file paths.\n",
    "    \"\"\"\n",
    "    return [f\"{base_path}/{file_name_pattern.format(str(i).zfill(4))}.{extension}\" for i in range(start, end + 1)]\n",
    "\n",
    "# Automating GIF files\n",
    "sample_gif_files = [\n",
    "    f\"input_data/sample_gif/SampleGIFImage_{size}kbmb.gif\"\n",
    "    for size in [40, 135, 350]\n",
    "]\n",
    "\n",
    "# Automating JPG files\n",
    "sample_jpg_files = [\n",
    "    f\"input_data/sample_jpg/SampleJPGImage_{size}mbmb.jpg\"\n",
    "    for size in [1, 2, 5, 10, 15, 20, 30]\n",
    "] + [\n",
    "    f\"input_data/sample_jpg/SampleJPGImage_{size}kbmb.jpg\"\n",
    "    for size in [50, 100, 200, 500]\n",
    "]\n",
    "\n",
    "# Automating PDF files\n",
    "sample_pdf_files = [f\"input_data/sample_pdf/SamplePDFFile_{size}mb.pdf\" for size in [5]]\n",
    "\n",
    "# Automating PNG files\n",
    "sample_png_files = [\n",
    "    f\"input_data/sample_png/SamplePNGImage_{size}mbmb.png\"\n",
    "    for size in [1, 3, 5, 10, 20, 30]\n",
    "] + [\n",
    "    f\"input_data/sample_png/SamplePNGImage_{size}kbmb.png\"\n",
    "    for size in [100, 200, 500]\n",
    "]\n",
    "\n",
    "# Automating PPT files\n",
    "sample_ppt_files = [\n",
    "    f\"input_data/sample_ppt/SamplePPTFile_{size}kb.ppt\"\n",
    "    for size in [500, 1000]\n",
    "]\n",
    "\n",
    "# Automating Text files\n",
    "sample_text_files = [\n",
    "    f\"input_data/sample_text/text_{size}.txt\"\n",
    "    for size in [10, 100, 1000, 10000, 100000, 1000000, 10000000]\n",
    "]\n",
    "\n",
    "# Automating Video files\n",
    "video_resolutions = ['360x240', '640x360', '720x480', '1280x720']\n",
    "video_sizes = [1, 2, 5, 10, 20, 30]\n",
    "sample_video_files = [\n",
    "    f\"input_data/sample_video/SampleVideo_{res}_{size}mb.mp4\"\n",
    "    for res in video_resolutions\n",
    "    for size in video_sizes\n",
    "]\n",
    "\n",
    "# Automating ZIP files\n",
    "sample_zip_files = [\n",
    "    f\"input_data/sample_zip/SampleZIPFile_{size}mbmb.zip\"\n",
    "    for size in [10, 20, 30, 50, 100]\n",
    "]\n",
    "\n",
    "# Automating Vectors\n",
    "vectors = generate_file_paths(\n",
    "    base_path=\"input_data/vectors\",\n",
    "    file_name_pattern=\"byte{}\",\n",
    "    start=0,\n",
    "    end=195,\n",
    "    extension=\"dat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# Define the hashing algorithms to test\n",
    "hashing_algorithms = {\n",
    "    \"MD5\": hashlib.md5,\n",
    "    \"SHA-1\": hashlib.sha1,\n",
    "    \"SHA-256\": hashlib.sha256,\n",
    "    \"SHA3-256\": hashlib.sha3_256,\n",
    "    \"Blake2b\": hashlib.blake2b\n",
    "}\n",
    "\n",
    "# Function to calculate entropy of a hash output\n",
    "def calculate_entropy(data):\n",
    "    \"\"\"\n",
    "    Calculates the Shannon entropy of the given data.\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return 0\n",
    "    frequency = {}\n",
    "    for byte in data:\n",
    "        frequency[byte] = frequency.get(byte, 0) + 1\n",
    "    total_bytes = len(data)\n",
    "    entropy = -sum((freq / total_bytes) * math.log2(freq / total_bytes) for freq in frequency.values())\n",
    "    return entropy\n",
    "\n",
    "# Function to hash a file with the given algorithm\n",
    "def hash_file(file_path, algorithm):\n",
    "    \"\"\"\n",
    "    Hashes the contents of a file using the specified algorithm.\n",
    "    \"\"\"\n",
    "    hasher = algorithm()\n",
    "    with open(file_path, 'rb') as file:\n",
    "        while chunk := file.read(8192):  # Read file in chunks\n",
    "            hasher.update(chunk)\n",
    "    return hasher.digest()\n",
    "\n",
    "# Automate vector file generation\n",
    "def generate_file_paths(base_path, file_name_pattern, start, end, extension):\n",
    "    \"\"\"\n",
    "    Generates a list of file paths with a specified pattern.\n",
    "    \"\"\"\n",
    "    return [f\"{base_path}/{file_name_pattern.format(str(i).zfill(4))}.{extension}\" for i in range(start, end + 1)]\n",
    "\n",
    "# Generate file paths for the vectors\n",
    "vectors = generate_file_paths(\n",
    "    base_path=\"input_data/vectors\",\n",
    "    file_name_pattern=\"byte{}\",\n",
    "    start=0,\n",
    "    end=195,\n",
    "    extension=\"dat\"\n",
    ")\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Perform hashing and entropy tests\n",
    "for file_path in vectors:\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    for algo_name, algo_func in hashing_algorithms.items():\n",
    "        hash_output = hash_file(file_path, algo_func)\n",
    "        entropy = calculate_entropy(hash_output)\n",
    "        results.append({\n",
    "            \"File\": os.path.basename(file_path),\n",
    "            \"Algorithm\": algo_name,\n",
    "            \"Hash\": hash_output.hex(),\n",
    "            \"Entropy\": entropy\n",
    "        })\n",
    "\n",
    "# Store results in a DataFrame for analysis\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Group by algorithm and calculate the average entropy for each algorithm\n",
    "grouped_df = df.groupby(\"Algorithm\").mean(numeric_only=True)[\"Entropy\"].reset_index()\n",
    "grouped_df.rename(columns={\"Entropy\": \"Average Entropy\"}, inplace=True)\n",
    "\n",
    "# Save to CSV for later use (optional)\n",
    "output_csv = \"hash_entropy_results.csv\"\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Save the average entropy DataFrame to another CSV (optional)\n",
    "average_entropy_csv = \"average_entropy_results.csv\"\n",
    "grouped_df.to_csv(average_entropy_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Hash</th>\n",
       "      <th>Entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>byte0000.dat</td>\n",
       "      <td>MD5</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>byte0000.dat</td>\n",
       "      <td>SHA-1</td>\n",
       "      <td>da39a3ee5e6b4b0d3255bfef95601890afd80709</td>\n",
       "      <td>4.321928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>byte0000.dat</td>\n",
       "      <td>SHA-256</td>\n",
       "      <td>e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b93...</td>\n",
       "      <td>4.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>byte0000.dat</td>\n",
       "      <td>SHA3-256</td>\n",
       "      <td>a7ffc6f8bf1ed76651c14756a061d662f580ff4de43b49...</td>\n",
       "      <td>4.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>byte0000.dat</td>\n",
       "      <td>Blake2b</td>\n",
       "      <td>786a02f742015903c6c6fd852552d272912f4740e15847...</td>\n",
       "      <td>5.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>MD5</td>\n",
       "      <td>c3e97dd6e97fb5125688c97f36720cbe</td>\n",
       "      <td>3.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>SHA-1</td>\n",
       "      <td>3cdf2936da2fc556bfa533ab1eb59ce710ac80e5</td>\n",
       "      <td>4.321928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>SHA-256</td>\n",
       "      <td>09fc96082d34c2dfc1295d92073b5ea1dc8ef8da95f14d...</td>\n",
       "      <td>4.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>SHA3-256</td>\n",
       "      <td>5ecdbae446010644dd235353f132c03fa21a1e6020a86e...</td>\n",
       "      <td>4.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>Blake2b</td>\n",
       "      <td>388a507aa909e01f549b7fd8e6094b0438e8a1ecc4db0d...</td>\n",
       "      <td>5.738205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           File Algorithm                                               Hash  \\\n",
       "0  byte0000.dat       MD5                   d41d8cd98f00b204e9800998ecf8427e   \n",
       "1  byte0000.dat     SHA-1           da39a3ee5e6b4b0d3255bfef95601890afd80709   \n",
       "2  byte0000.dat   SHA-256  e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b93...   \n",
       "3  byte0000.dat  SHA3-256  a7ffc6f8bf1ed76651c14756a061d662f580ff4de43b49...   \n",
       "4  byte0000.dat   Blake2b  786a02f742015903c6c6fd852552d272912f4740e15847...   \n",
       "5  byte0001.dat       MD5                   c3e97dd6e97fb5125688c97f36720cbe   \n",
       "6  byte0001.dat     SHA-1           3cdf2936da2fc556bfa533ab1eb59ce710ac80e5   \n",
       "7  byte0001.dat   SHA-256  09fc96082d34c2dfc1295d92073b5ea1dc8ef8da95f14d...   \n",
       "8  byte0001.dat  SHA3-256  5ecdbae446010644dd235353f132c03fa21a1e6020a86e...   \n",
       "9  byte0001.dat   Blake2b  388a507aa909e01f549b7fd8e6094b0438e8a1ecc4db0d...   \n",
       "\n",
       "    Entropy  \n",
       "0  4.000000  \n",
       "1  4.321928  \n",
       "2  4.937500  \n",
       "3  4.812500  \n",
       "4  5.812500  \n",
       "5  3.750000  \n",
       "6  4.321928  \n",
       "7  4.937500  \n",
       "8  4.875000  \n",
       "9  5.738205  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Average Entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blake2b</td>\n",
       "      <td>5.763810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MD5</td>\n",
       "      <td>3.941964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHA-1</td>\n",
       "      <td>4.238822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHA-256</td>\n",
       "      <td>4.888266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHA3-256</td>\n",
       "      <td>4.866534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm  Average Entropy\n",
       "0   Blake2b         5.763810\n",
       "1       MD5         3.941964\n",
       "2     SHA-1         4.238822\n",
       "3   SHA-256         4.888266\n",
       "4  SHA3-256         4.866534"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the hashing algorithms to test\n",
    "hashing_algorithms = {\n",
    "    \"MD5\": hashlib.md5,\n",
    "    \"SHA-1\": hashlib.sha1,\n",
    "    \"SHA-256\": hashlib.sha256,\n",
    "    \"SHA3-256\": hashlib.sha3_256,\n",
    "    \"Blake2b\": hashlib.blake2b\n",
    "}\n",
    "\n",
    "# Function to hash a file with the given algorithm\n",
    "def hash_file(file_path, algorithm):\n",
    "    \"\"\"\n",
    "    Hashes the contents of a file using the specified algorithm.\n",
    "    \"\"\"\n",
    "    hasher = algorithm()\n",
    "    with open(file_path, 'rb') as file:\n",
    "        while chunk := file.read(8192):  # Read file in chunks\n",
    "            hasher.update(chunk)\n",
    "    return hasher.digest()\n",
    "\n",
    "# Function to calculate byte frequencies\n",
    "def calculate_byte_frequencies(hash_output):\n",
    "    \"\"\"\n",
    "    Calculates the frequency of each byte (0-255) in the hash output.\n",
    "    \"\"\"\n",
    "    frequencies = np.zeros(256, dtype=int)  # Initialize an array for byte frequencies\n",
    "    for byte in hash_output:\n",
    "        frequencies[byte] += 1\n",
    "    return frequencies\n",
    "\n",
    "# Combine all file paths (replace with your full file list if needed)\n",
    "all_files = vectors  # Use the vector paths or other file groups\n",
    "\n",
    "# Initialize a list to store results\n",
    "uniform_results = []\n",
    "\n",
    "# Perform uniform distribution tests\n",
    "for file_path in all_files:\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    for algo_name, algo_func in hashing_algorithms.items():\n",
    "        hash_output = hash_file(file_path, algo_func)\n",
    "        byte_frequencies = calculate_byte_frequencies(hash_output)\n",
    "        # Measure uniformity: standard deviation of frequencies (lower is better)\n",
    "        std_dev = np.std(byte_frequencies)\n",
    "        uniform_results.append({\n",
    "            \"File\": os.path.basename(file_path),\n",
    "            \"Algorithm\": algo_name,\n",
    "            \"Standard Deviation\": std_dev\n",
    "        })\n",
    "\n",
    "# Store results in a DataFrame for analysis\n",
    "uniform_df = pd.DataFrame(uniform_results)\n",
    "\n",
    "# Group by algorithm to calculate average standard deviation for each algorithm\n",
    "uniform_summary = uniform_df.groupby(\"Algorithm\").mean(numeric_only=True)[\"Standard Deviation\"].reset_index()\n",
    "uniform_summary.rename(columns={\"Standard Deviation\": \"Average Standard Deviation\"}, inplace=True)\n",
    "\n",
    "# Save results to CSV for later analysis (optional)\n",
    "uniform_df.to_csv(\"hash_uniformity_results.csv\", index=False)\n",
    "uniform_summary.to_csv(\"average_uniformity_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>byte0000.dat</td>\n",
       "      <td>MD5</td>\n",
       "      <td>0.242061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>byte0000.dat</td>\n",
       "      <td>SHA-1</td>\n",
       "      <td>0.268368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>byte0000.dat</td>\n",
       "      <td>SHA-256</td>\n",
       "      <td>0.342327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>byte0000.dat</td>\n",
       "      <td>SHA3-256</td>\n",
       "      <td>0.364434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>byte0000.dat</td>\n",
       "      <td>Blake2b</td>\n",
       "      <td>0.484123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>MD5</td>\n",
       "      <td>0.272431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>SHA-1</td>\n",
       "      <td>0.268368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>SHA-256</td>\n",
       "      <td>0.342327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>SHA3-256</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>Blake2b</td>\n",
       "      <td>0.507752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           File Algorithm  Standard Deviation\n",
       "0  byte0000.dat       MD5            0.242061\n",
       "1  byte0000.dat     SHA-1            0.268368\n",
       "2  byte0000.dat   SHA-256            0.342327\n",
       "3  byte0000.dat  SHA3-256            0.364434\n",
       "4  byte0000.dat   Blake2b            0.484123\n",
       "5  byte0001.dat       MD5            0.272431\n",
       "6  byte0001.dat     SHA-1            0.268368\n",
       "7  byte0001.dat   SHA-256            0.342327\n",
       "8  byte0001.dat  SHA3-256            0.353553\n",
       "9  byte0001.dat   Blake2b            0.507752"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Average Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blake2b</td>\n",
       "      <td>0.499340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MD5</td>\n",
       "      <td>0.249218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHA-1</td>\n",
       "      <td>0.280106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHA-256</td>\n",
       "      <td>0.351211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHA3-256</td>\n",
       "      <td>0.355463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm  Average Standard Deviation\n",
       "0   Blake2b                    0.499340\n",
       "1       MD5                    0.249218\n",
       "2     SHA-1                    0.280106\n",
       "3   SHA-256                    0.351211\n",
       "4  SHA3-256                    0.355463"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_summary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping empty file: input_data/vectors/byte0000.dat\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the hashing algorithms to test\n",
    "hashing_algorithms = {\n",
    "    \"MD5\": hashlib.md5,\n",
    "    \"SHA-1\": hashlib.sha1,\n",
    "    \"SHA-256\": hashlib.sha256,\n",
    "    \"SHA3-256\": hashlib.sha3_256,\n",
    "    \"Blake2b\": hashlib.blake2b\n",
    "}\n",
    "\n",
    "# Function to hash data with the given algorithm\n",
    "def hash_data(data, algorithm):\n",
    "    \"\"\"\n",
    "    Hashes the given data using the specified algorithm.\n",
    "    \"\"\"\n",
    "    hasher = algorithm()\n",
    "    hasher.update(data)\n",
    "    return hasher.digest()  # Return as raw bytes for bit comparison\n",
    "\n",
    "# Function to flip a specific bit in a byte sequence\n",
    "def flip_bit(data, bit_index):\n",
    "    \"\"\"\n",
    "    Flips a single bit in a byte sequence at the specified bit index.\n",
    "    \"\"\"\n",
    "    if len(data) == 0:\n",
    "        raise ValueError(\"Cannot flip a bit in an empty input.\")\n",
    "    \n",
    "    byte_index = bit_index // 8\n",
    "    if byte_index >= len(data):\n",
    "        raise ValueError(f\"bit_index {bit_index} is out of range for the input data of length {len(data) * 8} bits.\")\n",
    "    \n",
    "    bit_in_byte = bit_index % 8\n",
    "    modified_data = bytearray(data)\n",
    "    modified_data[byte_index] ^= (1 << bit_in_byte)\n",
    "    return bytes(modified_data)\n",
    "\n",
    "# Function to calculate the percentage of bits that changed\n",
    "def calculate_bit_difference(hash1, hash2):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of bits that differ between two hash outputs.\n",
    "    \"\"\"\n",
    "    if len(hash1) != len(hash2):\n",
    "        raise ValueError(\"Hashes must be the same length for comparison.\")\n",
    "    bit_diff = sum(bin(byte1 ^ byte2).count('1') for byte1, byte2 in zip(hash1, hash2))\n",
    "    total_bits = len(hash1) * 8\n",
    "    return (bit_diff / total_bits) * 100\n",
    "\n",
    "# Combine all file paths (use vectors or other file groups as needed)\n",
    "all_files = vectors  # Example: using the previously defined vector file paths\n",
    "\n",
    "# Initialize a list to store results\n",
    "avalanche_results = []\n",
    "\n",
    "# Perform avalanche effect test\n",
    "for file_path in all_files:\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    with open(file_path, 'rb') as file:\n",
    "        original_data = file.read()\n",
    "    \n",
    "    # Skip empty files\n",
    "    if len(original_data) == 0:\n",
    "        print(f\"Skipping empty file: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Test each algorithm\n",
    "    for algo_name, algo_func in hashing_algorithms.items():\n",
    "        # Hash the original data\n",
    "        original_hash = hash_data(original_data, algo_func)\n",
    "        \n",
    "        # Flip a single bit in the input data\n",
    "        try:\n",
    "            flipped_data = flip_bit(original_data, 0)  # Flip the first bit (index 0)\n",
    "            flipped_hash = hash_data(flipped_data, algo_func)\n",
    "            \n",
    "            # Calculate bit difference\n",
    "            bit_diff_percentage = calculate_bit_difference(original_hash, flipped_hash)\n",
    "            \n",
    "            # Store results\n",
    "            avalanche_results.append({\n",
    "                \"File\": os.path.basename(file_path),\n",
    "                \"Algorithm\": algo_name,\n",
    "                \"Bit Difference (%)\": bit_diff_percentage\n",
    "            })\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing file {file_path} with algorithm {algo_name}: {e}\")\n",
    "\n",
    "# Store results in a DataFrame\n",
    "avalanche_df = pd.DataFrame(avalanche_results)\n",
    "\n",
    "# Calculate average bit difference for each algorithm\n",
    "avalanche_summary = avalanche_df.groupby(\"Algorithm\").mean(numeric_only=True).reset_index()\n",
    "avalanche_summary.rename(columns={\"Bit Difference (%)\": \"Average Bit Difference (%)\"}, inplace=True)\n",
    "\n",
    "# Save results to CSV for later use (optional)\n",
    "avalanche_df.to_csv(\"avalanche_effect_results.csv\", index=False)\n",
    "avalanche_summary.to_csv(\"avalanche_effect_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Bit Difference (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>MD5</td>\n",
       "      <td>46.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>SHA-1</td>\n",
       "      <td>58.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>SHA-256</td>\n",
       "      <td>55.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>SHA3-256</td>\n",
       "      <td>46.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>byte0001.dat</td>\n",
       "      <td>Blake2b</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>byte0002.dat</td>\n",
       "      <td>MD5</td>\n",
       "      <td>48.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>byte0002.dat</td>\n",
       "      <td>SHA-1</td>\n",
       "      <td>51.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>byte0002.dat</td>\n",
       "      <td>SHA-256</td>\n",
       "      <td>48.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>byte0002.dat</td>\n",
       "      <td>SHA3-256</td>\n",
       "      <td>46.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>byte0002.dat</td>\n",
       "      <td>Blake2b</td>\n",
       "      <td>49.804688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           File Algorithm  Bit Difference (%)\n",
       "0  byte0001.dat       MD5           46.093750\n",
       "1  byte0001.dat     SHA-1           58.125000\n",
       "2  byte0001.dat   SHA-256           55.078125\n",
       "3  byte0001.dat  SHA3-256           46.875000\n",
       "4  byte0001.dat   Blake2b           50.000000\n",
       "5  byte0002.dat       MD5           48.437500\n",
       "6  byte0002.dat     SHA-1           51.250000\n",
       "7  byte0002.dat   SHA-256           48.828125\n",
       "8  byte0002.dat  SHA3-256           46.093750\n",
       "9  byte0002.dat   Blake2b           49.804688"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avalanche_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Average Bit Difference (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blake2b</td>\n",
       "      <td>49.942909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MD5</td>\n",
       "      <td>49.627404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHA-1</td>\n",
       "      <td>50.016026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHA-256</td>\n",
       "      <td>50.036058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHA3-256</td>\n",
       "      <td>50.050080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm  Average Bit Difference (%)\n",
       "0   Blake2b                   49.942909\n",
       "1       MD5                   49.627404\n",
       "2     SHA-1                   50.016026\n",
       "3   SHA-256                   50.036058\n",
       "4  SHA3-256                   50.050080"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avalanche_summary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Average Bit Difference (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blake2b</td>\n",
       "      <td>49.991621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MD5</td>\n",
       "      <td>49.958594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHA-1</td>\n",
       "      <td>49.999187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHA-256</td>\n",
       "      <td>50.021563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHA3-256</td>\n",
       "      <td>49.994531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm  Average Bit Difference (%)\n",
       "0   Blake2b                   49.991621\n",
       "1       MD5                   49.958594\n",
       "2     SHA-1                   49.999187\n",
       "3   SHA-256                   50.021563\n",
       "4  SHA3-256                   49.994531"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "# Define the hashing algorithms to test\n",
    "hashing_algorithms = {\n",
    "    \"MD5\": hashlib.md5,\n",
    "    \"SHA-1\": hashlib.sha1,\n",
    "    \"SHA-256\": hashlib.sha256,\n",
    "    \"SHA3-256\": hashlib.sha3_256,\n",
    "    \"Blake2b\": hashlib.blake2b\n",
    "}\n",
    "\n",
    "# Function to generate a random string\n",
    "def generate_random_string(length=64):\n",
    "    \"\"\"\n",
    "    Generates a random string of the specified length.\n",
    "    \"\"\"\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "# Function to flip a specific bit in a string\n",
    "def flip_bit_in_string(data, bit_index):\n",
    "    \"\"\"\n",
    "    Flips a single bit in a string's binary representation.\n",
    "    \"\"\"\n",
    "    byte_index = bit_index // 8\n",
    "    bit_in_byte = bit_index % 8\n",
    "    modified_data = bytearray(data.encode('utf-8'))\n",
    "    if byte_index < len(modified_data):\n",
    "        modified_data[byte_index] ^= (1 << bit_in_byte)\n",
    "    return modified_data.decode('utf-8', errors='ignore')\n",
    "\n",
    "# Function to calculate the percentage of bits that changed\n",
    "def calculate_bit_difference(hash1, hash2):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of bits that differ between two hash outputs.\n",
    "    \"\"\"\n",
    "    if len(hash1) != len(hash2):\n",
    "        raise ValueError(\"Hashes must be the same length for comparison.\")\n",
    "    bit_diff = sum(bin(byte1 ^ byte2).count('1') for byte1, byte2 in zip(hash1, hash2))\n",
    "    total_bits = len(hash1) * 8\n",
    "    return (bit_diff / total_bits) * 100\n",
    "\n",
    "# Function to hash data using a specified algorithm\n",
    "def hash_data(data, algorithm):\n",
    "    \"\"\"\n",
    "    Hashes the given data using the specified algorithm.\n",
    "    \"\"\"\n",
    "    hasher = algorithm()\n",
    "    hasher.update(data.encode('utf-8'))\n",
    "    return hasher.digest()\n",
    "\n",
    "# Parameters for the test\n",
    "num_samples = 10000  # Number of random strings to generate\n",
    "string_length = 128  # Length of each random string\n",
    "\n",
    "# Initialize a list to store results\n",
    "avalanche_results = []\n",
    "\n",
    "# Perform the avalanche effect test\n",
    "for _ in range(num_samples):\n",
    "    original_string = generate_random_string(string_length)\n",
    "    \n",
    "    # Test each algorithm\n",
    "    for algo_name, algo_func in hashing_algorithms.items():\n",
    "        # Hash the original string\n",
    "        original_hash = hash_data(original_string, algo_func)\n",
    "        \n",
    "        # Flip a single bit in the string\n",
    "        flipped_string = flip_bit_in_string(original_string, 0)  # Flip the first bit\n",
    "        flipped_hash = hash_data(flipped_string, algo_func)\n",
    "        \n",
    "        # Calculate bit difference\n",
    "        bit_diff_percentage = calculate_bit_difference(original_hash, flipped_hash)\n",
    "        \n",
    "        # Store results\n",
    "        avalanche_results.append({\n",
    "            \"Original String\": original_string,\n",
    "            \"Algorithm\": algo_name,\n",
    "            \"Bit Difference (%)\": bit_diff_percentage\n",
    "        })\n",
    "\n",
    "# Store results in a DataFrame\n",
    "avalanche_df = pd.DataFrame(avalanche_results)\n",
    "\n",
    "# Calculate average bit difference for each algorithm\n",
    "avalanche_summary = avalanche_df.groupby(\"Algorithm\").mean(numeric_only=True).reset_index()\n",
    "avalanche_summary.rename(columns={\"Bit Difference (%)\": \"Average Bit Difference (%)\"}, inplace=True)\n",
    "\n",
    "# Save results to CSV for later use (optional)\n",
    "avalanche_df.to_csv(\"random_strings_avalanche_effect_results.csv\", index=False)\n",
    "avalanche_summary.to_csv(\"random_strings_avalanche_effect_summary.csv\", index=False)\n",
    "\n",
    "avalanche_df.head(10)\n",
    "avalanche_summary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Truncated Bits</th>\n",
       "      <th>Number of Samples</th>\n",
       "      <th>Collisions</th>\n",
       "      <th>Collision Probability (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MD5</td>\n",
       "      <td>32</td>\n",
       "      <td>100000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SHA-1</td>\n",
       "      <td>32</td>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHA-256</td>\n",
       "      <td>32</td>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHA3-256</td>\n",
       "      <td>32</td>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blake2b</td>\n",
       "      <td>32</td>\n",
       "      <td>100000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm  Truncated Bits  Number of Samples  Collisions  \\\n",
       "0       MD5              32             100000           3   \n",
       "1     SHA-1              32             100000           0   \n",
       "2   SHA-256              32             100000           1   \n",
       "3  SHA3-256              32             100000           0   \n",
       "4   Blake2b              32             100000           3   \n",
       "\n",
       "   Collision Probability (%)  \n",
       "0                      0.003  \n",
       "1                      0.000  \n",
       "2                      0.001  \n",
       "3                      0.000  \n",
       "4                      0.003  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "# Define the hashing algorithms to test\n",
    "hashing_algorithms = {\n",
    "    \"MD5\": hashlib.md5,\n",
    "    \"SHA-1\": hashlib.sha1,\n",
    "    \"SHA-256\": hashlib.sha256,\n",
    "    \"SHA3-256\": hashlib.sha3_256,\n",
    "    \"Blake2b\": hashlib.blake2b\n",
    "}\n",
    "\n",
    "# Function to generate a random string\n",
    "def generate_random_string(length=64):\n",
    "    \"\"\"\n",
    "    Generates a random string of the specified length.\n",
    "    \"\"\"\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "# Function to hash a string and truncate the hash\n",
    "def truncated_hash(data, algorithm, bits=16):\n",
    "    \"\"\"\n",
    "    Hashes the input data using the specified algorithm and truncates the output.\n",
    "    Args:\n",
    "        data (str): The input data to hash.\n",
    "        algorithm (function): The hash function from hashlib.\n",
    "        bits (int): The number of bits to keep from the hash output.\n",
    "    Returns:\n",
    "        str: The truncated hash as a hexadecimal string.\n",
    "    \"\"\"\n",
    "    hasher = algorithm()\n",
    "    hasher.update(data.encode('utf-8'))\n",
    "    full_hash = hasher.digest()\n",
    "    truncated_bytes = bits // 8  # Convert bits to bytes\n",
    "    return full_hash[:truncated_bytes].hex()\n",
    "\n",
    "# Parameters for the test\n",
    "num_samples = 100000  # Number of strings to generate\n",
    "truncated_bits = 32   # Number of bits to keep in the truncated hash space\n",
    "\n",
    "# Initialize results dictionary for collisions\n",
    "collision_results = []\n",
    "\n",
    "# Perform the collision detection test\n",
    "for algo_name, algo_func in hashing_algorithms.items():\n",
    "    hash_set = set()\n",
    "    collisions = 0\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        random_string = generate_random_string()\n",
    "        truncated_h = truncated_hash(random_string, algo_func, truncated_bits)\n",
    "        \n",
    "        if truncated_h in hash_set:\n",
    "            collisions += 1\n",
    "        else:\n",
    "            hash_set.add(truncated_h)\n",
    "    \n",
    "    collision_results.append({\n",
    "        \"Algorithm\": algo_name,\n",
    "        \"Truncated Bits\": truncated_bits,\n",
    "        \"Number of Samples\": num_samples,\n",
    "        \"Collisions\": collisions,\n",
    "        \"Collision Probability (%)\": (collisions / num_samples) * 100\n",
    "    })\n",
    "\n",
    "# Store results in a DataFrame\n",
    "collision_df = pd.DataFrame(collision_results)\n",
    "\n",
    "# Save results to CSV for later use (optional)\n",
    "collision_df.to_csv(\"collision_detection_results.csv\", index=False)\n",
    "\n",
    "# Display the results\n",
    "collision_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Truncated Bits</th>\n",
       "      <th>Target Hash</th>\n",
       "      <th>Preimage Found</th>\n",
       "      <th>Found Preimage</th>\n",
       "      <th>Attempts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MD5</td>\n",
       "      <td>16</td>\n",
       "      <td>abcd</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SHA-1</td>\n",
       "      <td>16</td>\n",
       "      <td>abcd</td>\n",
       "      <td>True</td>\n",
       "      <td>JlQikxZjloOmurJfYVjRLikDbeAwWwwe0pCNKqYzJMOGuB...</td>\n",
       "      <td>26265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHA-256</td>\n",
       "      <td>16</td>\n",
       "      <td>abcd</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHA3-256</td>\n",
       "      <td>16</td>\n",
       "      <td>abcd</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blake2b</td>\n",
       "      <td>16</td>\n",
       "      <td>abcd</td>\n",
       "      <td>True</td>\n",
       "      <td>jyp0vjfinXZUkMp98nTBBHTR2uYCdO4qNcdp1YEc7dE3FX...</td>\n",
       "      <td>27460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm  Truncated Bits Target Hash  Preimage Found  \\\n",
       "0       MD5              16        abcd           False   \n",
       "1     SHA-1              16        abcd            True   \n",
       "2   SHA-256              16        abcd           False   \n",
       "3  SHA3-256              16        abcd           False   \n",
       "4   Blake2b              16        abcd            True   \n",
       "\n",
       "                                      Found Preimage  Attempts  \n",
       "0                                               None    100000  \n",
       "1  JlQikxZjloOmurJfYVjRLikDbeAwWwwe0pCNKqYzJMOGuB...     26265  \n",
       "2                                               None    100000  \n",
       "3                                               None    100000  \n",
       "4  jyp0vjfinXZUkMp98nTBBHTR2uYCdO4qNcdp1YEc7dE3FX...     27460  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "# Define the hashing algorithms to test\n",
    "hashing_algorithms = {\n",
    "    \"MD5\": hashlib.md5,\n",
    "    \"SHA-1\": hashlib.sha1,\n",
    "    \"SHA-256\": hashlib.sha256,\n",
    "    \"SHA3-256\": hashlib.sha3_256,\n",
    "    \"Blake2b\": hashlib.blake2b\n",
    "}\n",
    "\n",
    "# Function to generate a random string\n",
    "def generate_random_string(length=64):\n",
    "    \"\"\"\n",
    "    Generates a random string of the specified length.\n",
    "    \"\"\"\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "# Function to hash a string and truncate the hash\n",
    "def truncated_hash(data, algorithm, bits=16):\n",
    "    \"\"\"\n",
    "    Hashes the input data using the specified algorithm and truncates the output.\n",
    "    Args:\n",
    "        data (str): The input data to hash.\n",
    "        algorithm (function): The hash function from hashlib.\n",
    "        bits (int): The number of bits to keep from the hash output.\n",
    "    Returns:\n",
    "        str: The truncated hash as a hexadecimal string.\n",
    "    \"\"\"\n",
    "    hasher = algorithm()\n",
    "    hasher.update(data.encode('utf-8'))\n",
    "    full_hash = hasher.digest()\n",
    "    truncated_bytes = bits // 8  # Convert bits to bytes\n",
    "    return full_hash[:truncated_bytes].hex()\n",
    "\n",
    "# Parameters for the test\n",
    "num_samples = 100000  # Number of attempts to find the preimage\n",
    "truncated_bits = 16   # Number of bits to keep in the truncated hash space\n",
    "target_hash = \"abcd\"  # Predefined target hash to match (in truncated space)\n",
    "\n",
    "# Initialize results\n",
    "preimage_results = []\n",
    "\n",
    "# Perform the preimage test\n",
    "for algo_name, algo_func in hashing_algorithms.items():\n",
    "    found_preimage = None\n",
    "    for _ in range(num_samples):\n",
    "        random_string = generate_random_string()\n",
    "        truncated_h = truncated_hash(random_string, algo_func, truncated_bits)\n",
    "        \n",
    "        if truncated_h == target_hash:\n",
    "            found_preimage = random_string\n",
    "            break\n",
    "    \n",
    "    preimage_results.append({\n",
    "        \"Algorithm\": algo_name,\n",
    "        \"Truncated Bits\": truncated_bits,\n",
    "        \"Target Hash\": target_hash,\n",
    "        \"Preimage Found\": found_preimage is not None,\n",
    "        \"Found Preimage\": found_preimage if found_preimage else \"None\",\n",
    "        \"Attempts\": _ + 1\n",
    "    })\n",
    "\n",
    "# Store results in a DataFrame\n",
    "preimage_df = pd.DataFrame(preimage_results)\n",
    "\n",
    "# Save results to CSV for later use (optional)\n",
    "preimage_df.to_csv(\"preimage_test_results.csv\", index=False)\n",
    "\n",
    "preimage_df.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Truncated Bits</th>\n",
       "      <th>Collision Found</th>\n",
       "      <th>Hamming Distance</th>\n",
       "      <th>Colliding Input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MD5</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>56</td>\n",
       "      <td>6QTDNONH0SalL54KqcVWTLMABd4OopPlY0CjQQ0k0gxLUe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SHA-1</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>79</td>\n",
       "      <td>o56BIm9MS0Hpn8Zn1VHatf4mph2iPOg8ru7A1zzDJ6iOMm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHA-256</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>126</td>\n",
       "      <td>DY82xKpGWR8m061LVUmakPsPEgwHjPM2njIzCieGB3J5pB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHA3-256</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>121</td>\n",
       "      <td>yOKDDc9vsFk6OS4zG22h61z01ekEmPZoCHIdOxWv3SZH6z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blake2b</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>246</td>\n",
       "      <td>Y9fNcvM5LFfpImhx2rirHhGL9ggfZVOX6LeBFhm7rWt4Jj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm  Truncated Bits  Collision Found  Hamming Distance  \\\n",
       "0       MD5              16             True                56   \n",
       "1     SHA-1              16             True                79   \n",
       "2   SHA-256              16             True               126   \n",
       "3  SHA3-256              16             True               121   \n",
       "4   Blake2b              16             True               246   \n",
       "\n",
       "                                     Colliding Input  \n",
       "0  6QTDNONH0SalL54KqcVWTLMABd4OopPlY0CjQQ0k0gxLUe...  \n",
       "1  o56BIm9MS0Hpn8Zn1VHatf4mph2iPOg8ru7A1zzDJ6iOMm...  \n",
       "2  DY82xKpGWR8m061LVUmakPsPEgwHjPM2njIzCieGB3J5pB...  \n",
       "3  yOKDDc9vsFk6OS4zG22h61z01ekEmPZoCHIdOxWv3SZH6z...  \n",
       "4  Y9fNcvM5LFfpImhx2rirHhGL9ggfZVOX6LeBFhm7rWt4Jj...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "# Define the hashing algorithms to test\n",
    "hashing_algorithms = {\n",
    "    \"MD5\": hashlib.md5,\n",
    "    \"SHA-1\": hashlib.sha1,\n",
    "    \"SHA-256\": hashlib.sha256,\n",
    "    \"SHA3-256\": hashlib.sha3_256,\n",
    "    \"Blake2b\": hashlib.blake2b\n",
    "}\n",
    "\n",
    "# Function to generate a random string\n",
    "def generate_random_string(length=64):\n",
    "    \"\"\"\n",
    "    Generates a random string of the specified length.\n",
    "    \"\"\"\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "# Function to hash a string\n",
    "def hash_string(data, algorithm):\n",
    "    \"\"\"\n",
    "    Hashes the input data using the specified algorithm.\n",
    "    \"\"\"\n",
    "    hasher = algorithm()\n",
    "    hasher.update(data.encode('utf-8'))\n",
    "    return hasher.digest()  # Full binary hash\n",
    "\n",
    "# Function to truncate the hash\n",
    "def truncate_hash(full_hash, bits):\n",
    "    \"\"\"\n",
    "    Truncates the full hash to a specified number of bits.\n",
    "    \"\"\"\n",
    "    truncated_bytes = bits // 8  # Convert bits to bytes\n",
    "    return full_hash[:truncated_bytes].hex()\n",
    "\n",
    "# Function to calculate the Hamming Distance\n",
    "def calculate_hamming_distance(hash1, hash2):\n",
    "    \"\"\"\n",
    "    Calculates the Hamming Distance between two binary hash outputs.\n",
    "    \"\"\"\n",
    "    if len(hash1) != len(hash2):\n",
    "        raise ValueError(\"Hashes must be the same length for Hamming Distance calculation.\")\n",
    "    bit_diff = sum(bin(byte1 ^ byte2).count('1') for byte1, byte2 in zip(hash1, hash2))\n",
    "    return bit_diff\n",
    "\n",
    "# Parameters for the test\n",
    "num_samples = 100000  # Number of random strings to generate\n",
    "truncated_bits = 16   # Number of bits for truncated hash space\n",
    "\n",
    "# Initialize results\n",
    "collision_results = []\n",
    "\n",
    "# Perform the collision test and calculate Hamming Distances\n",
    "for algo_name, algo_func in hashing_algorithms.items():\n",
    "    hash_map = {}\n",
    "    for _ in range(num_samples):\n",
    "        random_string = generate_random_string()\n",
    "        full_hash = hash_string(random_string, algo_func)\n",
    "        truncated_h = truncate_hash(full_hash, truncated_bits)\n",
    "        \n",
    "        if truncated_h in hash_map:\n",
    "            # Collision found\n",
    "            original_hash = hash_map[truncated_h]\n",
    "            hamming_distance = calculate_hamming_distance(full_hash, original_hash)\n",
    "            collision_results.append({\n",
    "                \"Algorithm\": algo_name,\n",
    "                \"Truncated Bits\": truncated_bits,\n",
    "                \"Collision Found\": True,\n",
    "                \"Hamming Distance\": hamming_distance,\n",
    "                \"Colliding Input\": random_string\n",
    "            })\n",
    "            break\n",
    "        else:\n",
    "            hash_map[truncated_h] = full_hash\n",
    "\n",
    "# Store results in a DataFrame\n",
    "collision_df = pd.DataFrame(collision_results)\n",
    "\n",
    "# Calculate summary statistics for Hamming Distances\n",
    "hamming_summary = collision_df.groupby(\"Algorithm\").agg({\n",
    "    \"Hamming Distance\": [\"mean\", \"std\", \"min\", \"max\"]\n",
    "}).reset_index()\n",
    "hamming_summary.columns = [\"Algorithm\", \"Mean Hamming Distance\", \"Std Dev\", \"Min Hamming Distance\", \"Max Hamming Distance\"]\n",
    "\n",
    "# Save results to CSV for later use (optional)\n",
    "collision_df.to_csv(\"hamming_distance_collisions.csv\", index=False)\n",
    "hamming_summary.to_csv(\"hamming_distance_summary.csv\", index=False)\n",
    "\n",
    "collision_df.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Mean Hamming Distance</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Min Hamming Distance</th>\n",
       "      <th>Max Hamming Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blake2b</td>\n",
       "      <td>246.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MD5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHA-1</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHA-256</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHA3-256</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm  Mean Hamming Distance  Std Dev  Min Hamming Distance  \\\n",
       "0   Blake2b                  246.0      NaN                   246   \n",
       "1       MD5                   56.0      NaN                    56   \n",
       "2     SHA-1                   79.0      NaN                    79   \n",
       "3   SHA-256                  126.0      NaN                   126   \n",
       "4  SHA3-256                  121.0      NaN                   121   \n",
       "\n",
       "   Max Hamming Distance  \n",
       "0                   246  \n",
       "1                    56  \n",
       "2                    79  \n",
       "3                   126  \n",
       "4                   121  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_summary.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
