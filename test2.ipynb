{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Algorithm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 83\u001b[0m\n\u001b[1;32m     80\u001b[0m collision_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(collision_results)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Calculate summary statistics for Hamming Distances\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m hamming_summary \u001b[38;5;241m=\u001b[39m collision_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlgorithm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHamming Distance\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     85\u001b[0m })\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     86\u001b[0m hamming_summary\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlgorithm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Hamming Distance\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStd Dev\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMin Hamming Distance\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax Hamming Distance\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Save results to CSV for later use (optional)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   9184\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9185\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[1;32m   9186\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   9187\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   9188\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[1;32m   9189\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   9190\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[1;32m   9191\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[1;32m   9192\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[1;32m   9193\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[1;32m   1330\u001b[0m         obj,\n\u001b[1;32m   1331\u001b[0m         keys,\n\u001b[1;32m   1332\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   1333\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   1334\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   1335\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[1;32m   1336\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[1;32m   1337\u001b[0m     )\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Algorithm'"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "# Define the hashing algorithms to test\n",
    "hashing_algorithms = {\n",
    "    \"MD5\": hashlib.md5,\n",
    "    \"SHA-1\": hashlib.sha1,\n",
    "    \"SHA-256\": hashlib.sha256,\n",
    "    \"SHA3-256\": hashlib.sha3_256,\n",
    "    \"Blake2b\": hashlib.blake2b\n",
    "}\n",
    "\n",
    "# Function to generate a random string\n",
    "def generate_random_string(length=64):\n",
    "    \"\"\"\n",
    "    Generates a random string of the specified length.\n",
    "    \"\"\"\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "# Function to hash a string\n",
    "def hash_string(data, algorithm):\n",
    "    \"\"\"\n",
    "    Hashes the input data using the specified algorithm.\n",
    "    \"\"\"\n",
    "    hasher = algorithm()\n",
    "    hasher.update(data.encode('utf-8'))\n",
    "    return hasher.digest()  # Full binary hash\n",
    "\n",
    "# Function to truncate the hash\n",
    "def truncate_hash(full_hash, bits):\n",
    "    \"\"\"\n",
    "    Truncates the full hash to a specified number of bits.\n",
    "    \"\"\"\n",
    "    truncated_bytes = bits // 8  # Convert bits to bytes\n",
    "    return full_hash[:truncated_bytes].hex()\n",
    "\n",
    "# Function to calculate the Hamming Distance\n",
    "def calculate_hamming_distance(hash1, hash2):\n",
    "    \"\"\"\n",
    "    Calculates the Hamming Distance between two binary hash outputs.\n",
    "    \"\"\"\n",
    "    if len(hash1) != len(hash2):\n",
    "        raise ValueError(\"Hashes must be the same length for Hamming Distance calculation.\")\n",
    "    bit_diff = sum(bin(byte1 ^ byte2).count('1') for byte1, byte2 in zip(hash1, hash2))\n",
    "    return bit_diff\n",
    "\n",
    "# Parameters for the test\n",
    "num_samples = 100000  # Number of random strings to generate\n",
    "truncated_bits = 64   # Number of bits for truncated hash space\n",
    "\n",
    "# Initialize results\n",
    "collision_results = []\n",
    "\n",
    "# Perform the collision test and calculate Hamming Distances\n",
    "for algo_name, algo_func in hashing_algorithms.items():\n",
    "    hash_map = {}\n",
    "    for _ in range(num_samples):\n",
    "        random_string = generate_random_string()\n",
    "        full_hash = hash_string(random_string, algo_func)\n",
    "        truncated_h = truncate_hash(full_hash, truncated_bits)\n",
    "        \n",
    "        if truncated_h in hash_map:\n",
    "            # Collision found\n",
    "            original_hash = hash_map[truncated_h]\n",
    "            hamming_distance = calculate_hamming_distance(full_hash, original_hash)\n",
    "            collision_results.append({\n",
    "                \"Algorithm\": algo_name,\n",
    "                \"Truncated Bits\": truncated_bits,\n",
    "                \"Collision Found\": True,\n",
    "                \"Hamming Distance\": hamming_distance,\n",
    "                \"Colliding Input\": random_string\n",
    "            })\n",
    "            break\n",
    "        else:\n",
    "            hash_map[truncated_h] = full_hash\n",
    "\n",
    "# Store results in a DataFrame\n",
    "collision_df = pd.DataFrame(collision_results)\n",
    "\n",
    "# Calculate summary statistics for Hamming Distances\n",
    "hamming_summary = collision_df.groupby(\"Algorithm\").agg({\n",
    "    \"Hamming Distance\": [\"mean\", \"std\", \"min\", \"max\"]\n",
    "}).reset_index()\n",
    "hamming_summary.columns = [\"Algorithm\", \"Mean Hamming Distance\", \"Std Dev\", \"Min Hamming Distance\", \"Max Hamming Distance\"]\n",
    "\n",
    "# Save results to CSV for later use (optional)\n",
    "collision_df.to_csv(\"hamming_distance_collisions.csv\", index=False)\n",
    "hamming_summary.to_csv(\"hamming_distance_summary.csv\", index=False)\n",
    "\n",
    "collision_df.head(15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
